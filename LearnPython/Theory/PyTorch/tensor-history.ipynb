{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab45fc3e",
   "metadata": {},
   "source": [
    "## Stop a tensor from tracking history:\n",
    "\n",
    "For example during the training loop when we want to update our weights, or after training during evaluation. These operation part of the gradient computation. To prevent this, we can use:\n",
    "\n",
    "- x.requires_grad(False)\n",
    "- x.detach()\n",
    "- wrap in with torch.no_grad():\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a847147",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be6e796f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "None\n",
      "True\n",
      "<SumBackward0 object at 0x0000025392F16BC0>\n"
     ]
    }
   ],
   "source": [
    "# .requires_grad(...) changes on existing falg in-place \n",
    "a = torch.randn(2, 2)\n",
    "b = (a*a).sum()\n",
    "print(a.requires_grad)\n",
    "print(b.grad_fn)\n",
    "\n",
    "a.requires_grad_(True)\n",
    "b = (a*a).sum()\n",
    "print(a.requires_grad)\n",
    "print(b.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f2db17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# .deatch(): get a new tensor with the same content but no gradient computation: \n",
    "a = torch.randn(2, 2, requires_grad=True)\n",
    "b = a.detach()\n",
    "print(a.requires_grad)\n",
    "print(b.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eab2aca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# wrap in 'with torch.no_grad()'\n",
    "a = torch.randn(2, 2, requires_grad=True)\n",
    "print(a.requires_grad)\n",
    "with torch.no_grad(): \n",
    "    b = a** 2\n",
    "    print(b.requires_grad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
