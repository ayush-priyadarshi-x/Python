{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e01fb34",
   "metadata": {},
   "source": [
    "### 1. Tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef3bedc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty(1): tensor([-4.1246e+11])\n",
      "empty(3): tensor([0., 0., 0.])\n",
      "empty(2,3): tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "empty(2, 2, 3): tensor([[[0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.]]])\n",
      "rand(5,3): tensor([[0.3483, 0.0935, 0.5112],\n",
      "        [0.2793, 0.2186, 0.3692],\n",
      "        [0.0696, 0.5560, 0.3710],\n",
      "        [0.7165, 0.8387, 0.7937],\n",
      "        [0.8822, 0.8945, 0.7685]])\n",
      "zeros(5,3): tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# torch.empty(size): uninitiallized\n",
    "x = torch.empty(1) # scalar\n",
    "print(\"empty(1):\", x)\n",
    "x = torch.empty(3) # vector\n",
    "print(\"empty(3):\",x)\n",
    "x = torch.empty(2, 3) # matrix\n",
    "print(\"empty(2,3):\",x)\n",
    "x = torch.empty(2, 2, 3) # tensor, 3 dimensions\n",
    "#x = torch.empty(2,2,2,3) # tensor, 4 dimensions\n",
    "print(\"empty(2, 2, 3):\",x)\n",
    "\n",
    "# torch.rand(size): random numbers [0, 1]\n",
    "x = torch.rand(5, 3)\n",
    "print(\"rand(5,3):\", x)\n",
    "\n",
    "# torch.zeros(size), fill with 0\n",
    "# torch.ones(size), fill with 1\n",
    "x = torch.zeros(5, 3)\n",
    "print(\"zeros(5,3):\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8a79378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size :  torch.Size([5, 3])\n",
      "Shape :  torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "# Check Size \n",
    "print(\"Size : \" , x.size())\n",
    "print(\"Shape : \" , x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28223ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], dtype=torch.float16)\n",
      "torch.float16\n"
     ]
    }
   ],
   "source": [
    "# Check Datatype\n",
    "print(x.dtype)\n",
    "\n",
    "# Spcify types, float32 default\n",
    "x = torch.zeros(5,3, dtype=torch.float16)\n",
    "print(x)\n",
    "\n",
    "# Check Type\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90146c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 5, 3]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "# Construct from data \n",
    "x  = torch.tensor([5, 5, 3 ])\n",
    "print(x, x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95eca6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Requires_grad argument \n",
    "# This will tell pytorch that it will need to calcuate the gradient for this tensor \n",
    "# Later in your optimization steps \n",
    "# i.e. this is a variable in your model that you want to optimize \n",
    "\n",
    "x = torch.tensor([5.5,3], requires_grad=True)\n",
    "print(x) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4030623d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor([[0.1235, 0.1542],\n",
      "        [0.0303, 0.9287]])\n",
      "Addition :  tensor([[1.1235, 1.1542],\n",
      "        [1.0303, 1.9287]])\n",
      "Subtraction :  tensor([[0.8765, 0.8458],\n",
      "        [0.9697, 0.0713]])\n",
      "Multiplication :  tensor([[0.1235, 0.1542],\n",
      "        [0.0303, 0.9287]])\n",
      "Division :  tensor([[ 8.0940,  6.4846],\n",
      "        [32.9575,  1.0768]])\n"
     ]
    }
   ],
   "source": [
    "# Operations\n",
    "x = torch.ones(2, 2)\n",
    "y = torch.rand(2, 2)\n",
    "\n",
    "# Elementwise addition\n",
    "z = x + y\n",
    "torch.add(x,y)\n",
    "# torch.add(x,y)\n",
    "\n",
    "#In plane addition, everything with a  trailing underscore is a inplace operation\n",
    "#i.e. it will modify the variable\n",
    "# y.add_(x)\n",
    "\n",
    "print(x)\n",
    "print(y)\n",
    "print(\"Addition : \", z)\n",
    "\n",
    "z = x - y \n",
    "torch.sub(x, y)\n",
    "print(\"Subtraction : \", z)\n",
    "\n",
    "z = x * y \n",
    "torch.mul(x, y)\n",
    "print(\"Multiplication : \", z)\n",
    "\n",
    "z = x / y \n",
    "torch.div(x, y)\n",
    "print(\"Division : \", z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da5d2a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3838, 0.3710, 0.6569],\n",
      "        [0.5449, 0.5527, 0.6332],\n",
      "        [0.0711, 0.9078, 0.8720],\n",
      "        [0.3815, 0.1849, 0.2858],\n",
      "        [0.2061, 0.3853, 0.9112]])\n",
      "X[: , 0]  tensor([0.3838, 0.5449, 0.0711, 0.3815, 0.2061])\n",
      "X[1, :]  tensor([0.5449, 0.5527, 0.6332])\n",
      "X[1, 1]  tensor(0.5527)\n",
      "x[1, 1].item()  0.5526584982872009\n"
     ]
    }
   ],
   "source": [
    "# Slicing \n",
    "x = torch.rand(5, 3)\n",
    "print(x)\n",
    "print(\"X[: , 0] \", x[: , 0 ])\n",
    "print(\"X[1, :] \", x[1, :  ])\n",
    "print(\"X[1, 1] \", x[1, 1])\n",
    "\n",
    "print(\"x[1, 1].item() \", x[1,1].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "180a5db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "# Reshape with torch.view()\n",
    "x = torch.randn(4, 4) \n",
    "y = x.view(16) # Shapes the x as (16, ) in y\n",
    "z = x.view(-1, 8) # The -1 tells PyTorch to infer the appropriate dimension automatically based on the total number of elements\n",
    "\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a34a89",
   "metadata": {},
   "source": [
    "### NumPy\n",
    "\n",
    "#### Converting a Torch to a NumPy array and vice versa is very easy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0dd115c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.ones(5)\n",
    "print(a)\n",
    "\n",
    "b = a.numpy()\n",
    "print(b)\n",
    "print(type(b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9ed2a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Numpy to torch with .from_numpy(x), or torch.tensor() to copy it \n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "c = torch.tensor(a)\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "\n",
    "# Again be careful when modifying\n",
    "a += 1 \n",
    "print(a)\n",
    "print(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e7bd7b",
   "metadata": {},
   "source": [
    "### GPU Support\n",
    "\n",
    "#### By default are created on the CPU. But we can also move them to the GPU (if it's available), or create them direcly on the GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8b2fca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "x = torch.rand(2, 2).to(device) # Move tensors to GPU device \n",
    "# x = a.to(\"cpu\")\n",
    "# x = x.to('cuda')\n",
    "\n",
    "x = torch.rand(2, 2, device=device) # or directly create them on GPU "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5486ef0a",
   "metadata": {},
   "source": [
    "### 2. Autograd\n",
    "\n",
    "The autograd package provides automatic differentiation for all operations on Tensors. Generally speaking, torch.autograd is an engine for computing the vector-Jacobian product. It computes partial derivatives while applying the chain rule.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac8c23f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1092, -0.4746,  0.2976], requires_grad=True)\n",
      "tensor([1.8908, 1.5254, 2.2976], grad_fn=<AddBackward0>)\n",
      "<AddBackward0 object at 0x000001A4E47B0C70>\n"
     ]
    }
   ],
   "source": [
    "# requires_grad = True --> tracks all operations on the tensor. \n",
    "x = torch.randn(3, requires_grad=True )\n",
    "y = x + 2 \n",
    "\n",
    "# y was created as a result of an operation, so it has a grad_fn attribute\n",
    "# grad_fn: references a Function that has created the Tensor\n",
    "print(x)\n",
    "print(y)\n",
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99a886d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10.7248,  6.9805, 15.8373], grad_fn=<MulBackward0>)\n",
      "tensor(11.1809, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Do more operations of y \n",
    "z = y * y * 3\n",
    "print(z)\n",
    "z = z.mean()\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc8c59cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10.7248,  6.9805, 15.8373], grad_fn=<MulBackward0>)\n",
      "tensor(11.1809, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Let's compute the graidients with backpropogation\n",
    "# When we finish our computation we can  call .backward() and have all the gradients computer automatically. \n",
    "# The gradient for this tensor will be accumulated into .grad attribute. \n",
    "# It is the partial derivate of the function w.r.t. the tensor\n",
    "\n",
    "z = y * y * 3\n",
    "print(z)\n",
    "z = z.mean()\n",
    "print(z)\n",
    "\n",
    "\n",
    "# ! ! ! Careful ! ! ! backward() accumulate the gradient for this tensor into .grad attribute. \n",
    "# ! ! ! We need to be careful during optimization ! ! ! optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b773b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.7815, 3.0508, 4.5953])\n"
     ]
    }
   ],
   "source": [
    "z.backward()\n",
    "print(x.grad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
